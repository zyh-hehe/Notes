# <center> 操作系统概念 </center>

## <center>    noted by zyh-hehe   </center>

##  <center> BUPT SCS 2022</center>

![](pic/0-0.jpg)

### 第一章 导论

#### 1.1 操作系统的功能

##### 一. 计算机系统的组件：硬件、操作系统、应用程序、用户

1. 硬件：为系统提供基本的计算资源
2. 应用程序：规定用户为解决计算问题而使用这些资源的方式
3. 操作系统：控制硬件，并协调各个用户应用程序的硬件使用

<img src="pic/1-1.jpg" style="zoom:50%;" />

##### 二. 用户视角

1. 单个用户单独使用资源：优化用户进行的工作。设计主要目的是用户使用方便，次要的是性能，不在乎的是资源利用（如何共享硬件和软件资源）
2. 多个用户共享资源并可以交换信息：设计主要目的是优化资源利用率，确保所有的cpu时间、内存和IO都能得到有效使用，并且确保没有用户使用超过限额以外的资源
3. 工作站模式，工作站和其他工作站和服务器相连，用户不仅可以使用专用资源，而且可以使用网络和服务器的共享资源：设计需要兼顾使用方便性和资源利用率

##### 三. 系统视角

1. 从计算机的角度来看，操作系统是与硬件紧密相连的程序。因此可以将操作系统看作资源分配器。
2. 计算机系统的资源：cpu时间、内存空间、文件存储空间、IO设备等。
3. 控制程序角度：强调控制各种IO设备和用户程序的需求，操作系统作为控制程序管理用户程序的执行，以防止计算机资源的错误或不当使用。特别注重IO设备的运行和控制。

##### 四. 操作系统的定义

1. 一个比较公认的定义是，**操作系统是一直运行在计算机上的程序（内核/kernel）**。（除了内核外，还有其他的两类程序：系统程序和应用程序。前者是与系统运行有关的程序，但不是内核的一部分；后者是与系统运行无关的所有其他程序）
2. 移动操作系统通常不只有内核，也有中间件，即为应用程序开发人员提供其他功能（如数据、多媒体和图形等）的软件框架。

#### 1.2 计算机系统的组成

##### 一. 计算机系统的运行

1. 现代通用计算机系统包括**一个或多个cpu**和**若干设备控制器**，通过**公用总线**相连而成，该总线提供了共享内存的访问。每个设备控制器负责一类特定的设备。cpu和设备控制器可以并发执行，并且竞争访问内存。为了确保有序访问共享内存，需要内存控制器来协调访问内存。

   <img src="pic/1-2.jpg" style="zoom:50%;" />

2. 当计算机开始运行时，它需要运行一个**初始程序**。该初始程序/引导程序一般位于计算机的固件（如ROM或EEPROM）。它初始化系统的各个组件，从cpu寄存器、设备控制器到内存内容。引导程序必须知道如何加载操作系统并且开始执行系统，所以**其必须定位操作系统内核并且加到内存**。

3. 一旦内核**加到内存并执行**，它就开始为系统和用户提供服务。除了内核外，系统程序也提供一些服务，它们在启动时加到内存而成为系统进程/系统后台程序，其生命周期与内核一样。对于UNIX，首个系统进程为”init“，它允许许多其他系统后台程序。一旦这个阶段完成了，系统就完全启动了，并且等待事件发生。

4. 事件发生通常通过软硬件的中断来通知。硬件可以随时通过系统总线发送信号到cpu以触发中断，而软件也可通过执行特别操作即系统调用（监督程序调用）以触发中断。

##### 二. 存储结构

<img src="pic/1-3.jpg" style="zoom:50%;" />

##### 三. IO结构

1. 通用计算机系统包括一个或多个cpu和若干设备控制器，通过公用总线相连而成，每个设备控制器负责一类特定的设备。每个设备控制器维护一定量的本地缓冲存储和一组特定用途的寄存器。设备控制器负责在所控制的外围设备与本地缓冲存储之间进行数据传递。操作系统为每个设备控制器提供一个设备驱动程序，该程序负责设备控制器并为操作系统的其他部分提供统一的设备访问接口。
2. 在开始IO时，设备驱动程序加载设备控制器的适当寄存器。相应的，设备控制器检查这些寄存器内容并决定采取什么操作（如读取字符）。控制器开始从设备向本地缓冲区传输数据。一旦完成数据传输，设备控制器就会发出中断表明操作完成，然后驱动程序将控制返回到操作系统。对于读操作，数据或数据指针也会返回；对于其他操作，返回状态信息。
3. DMA：设备控制器可在本地缓冲和内存之间传送整块的数据而无需cpu的干预。

<img src="pic/1-4.jpg" style="zoom:50%;" />

#### 1.3 计算机系统的体系结构

##### 一. 单处理器系统

1. 单处理器系统只有一个主cpu以便执行一个通用指令集，该指令集包括执行用户进程的指令。几乎所有单处理器系统都带有其他专用处理器（如IO处理器等）。这些专用处理器执行有限指令集，而且不执行用户进程。在有的环境下，它们由操作系统管理，操作系统将要做的任务信息发给它们并监控他们的状态。在其他的环境下，专用处理器作为底层组件集成到硬件。操作系统不能和这些处理器通信，但它们可以自主完成任务。要注意的一点是，**如果系统只有一个通用cpu，那么就为单处理器系统**。

##### 二. 多处理器系统

1. 多处理器系统有两个或多个紧密通信的cpu，它们共享计算机总线，有的还共享时钟、内存和外设等。
2. 多处理器系统的优点：增加吞吐量、规模经济、增加可靠性。
   - 增加吞吐量：通过增加处理器数量，能够在更短时间内完成更多工作。采用N个处理器的加速比小于N（**阿姆达尔定律**）。
   - 规模经济：多处理器系统可以共享外设、大容量存储和电源供给。
   - 增加可靠性：将功能分布在多个处理器上，单个处理器的失灵不会使整个系统停止，而只会变慢。
3. 适度退化和容错：根据剩余有效硬件的级别按比例提供服务的能力称为**适度退化**。有的系统超过适度退化，称为容错，因为它们能容忍单个部件错误并且仍然继续运行。容错需要一定的机制来对故障进行检测、诊断和纠错
4. 非对称处理：每个处理器都有各自特定的任务，一个主处理器控制系统，其他处理器或向主处理器要任务或做预先规定的任务。这种方案称为主从关系，即主处理器调度从处理器并安排工作。
5. <a name="SMP">对称多处理（SMP）</a>：每个处理器都参与完成操作系统的所有任务。每个处理器都有自己的寄存器集，也有私有或本地缓存；但所有处理器都共享物理内存。

<img src="pic/1-5.jpg" style="zoom:50%;" />

6. 对称和非对称处理的差异可能源于硬件或者软件。特定硬件可以区别多个处理器，软件也可编成选择一个处理器为主，其他的为从。
7. **多处理通过增加cpu来提高计算能力**。如果cpu集成了内存控制器，那么增加cpu也能增大系统的内存访问。无论如何，多处理可使系统的内存访问模型从均匀内存访问（UMA）改成非均匀内存访问（NUMA）。对于UMA，cpu访问RAM的所需时间相同；而对NUMA，有的内存访问所需时间更多，这会降低性能。操作系统通过资源管理可以改善NUMA的问题。
8. 多核设计：集成多个计算核到单个芯片。多核比多个单核更加高效，因为单片通信比多个芯片通信更快，且电源消耗更低。要注意的是，多核系统为多处理器系统，但不是所有多处理器系统都是多核的
9. 刀片服务器：将多处理器板、IO板和网络板全部置于同一机箱。和传统多处理器系统不同的是，每个刀片服务器可以独立启动，并且运行各自的操作系统。

##### 三. 集群系统

1. 与多处理器系统不同，集群系统由两个或多个独立系统（或节点）组成。这样的系统是**松耦合**的，每个节点可为单处理器系统或多核系统。集群系统较为公认的定义是，集群计算机共享存储，并且采用局域网连接或更快的内部连接。
2. 集群通常**用于提供高可用性服务**，这意味着即使集群中的一个或多个系统出错，仍可继续提供服务。一般来说，通过在系统中增加一定冗余可获取高可用性，每个集群节点都可执行集群软件层，以监视（通过局域网）一个或多个其他节点。如果被监视的机器失效，那么监视机器可以取代存储的拥有权并重启在失效机器上运行的应用程序。用户只会感到短暂的服务中止。
3. 集群可以是对称的或非对称的。对于**非对称集群**，一台机器处于热备份模式，而另一台运行应用程序，热备份主机只监视活动服务器。对于**对称集群**，两个或多个主机都运行应用程序并互相监视。这种方式充分使用现有硬件，当有多个应用程序可供执行时，这种结构更为高效。
4. 集群也可以提供高性能计算环境。每个集群的所有计算机可以并发执行一个应用程序，提供更强大的计算能力。这种技术就是**并行计算**，即将一个程序分为多个部分，而每个部分可以并行运行在计算机或集群计算机的各个核上。每个集群节点解决部分问题，结果合并形成最终解决方案。
5. 其它形式的集群：并行集群允许多个主机访问共享存储的统一数据。

#### 1.4 操作系统的结构

##### 一. 多道程序设计

1. 单个程序不会一直占用cpu和IO设备，多道程序设计通过**合理安排作业**提高cpu利用率。
2. 操作系统会在内存中保存多个任务，但主存太小不能容纳所有作业，因此这些作业会保存在硬盘的**作业池**上，等待分配内存。
3. **内存的作业集**是作业池的作业集的子集。操作系统可以从其中选择执行一个作业。当这个作业需要等待时，cpu可以简单切换到另一个作业。

##### 二. 分时系统

1. 分时系统又称多任务，是多道程序设计的自然延伸。
2. 还是通过cpu切换作业来执行多个作业，但切换频率很高，用户可以在程序运行时与其交互。
3. 允许多个用户共享一台计算机。由于每个动作一般较短，所以每个用户只需要少量cpu时间。系统在用户之间快速切换，实现了每个用户都感觉整个系统为自己所用。
4. 对于分时系统，操作系统必须**确保合理的响应时间**。这可以通过交换实现，但更好的实现方式是虚拟内存。

#### 1.5 操作系统的执行

##### 一. 双重模式与多重模式的执行

1. 为了确保操作系统正确运行，必须区分操作系统代码和用户代码的执行。大多数计算机系统采用**硬件支持**来区分执行模式。

2. 常见的两种单独运行模式是用户模式和内核模式（监视模式、系统模式、特权模式）。**硬件可以通过一个模式位（0/1）区分两种模式。**执行用户程序时系统处于用户模式，但用户程序通过系统调用请求操作系统服务时，系统就会切换到内核模式。

   <img src="pic/1-6.jpg" style="zoom:50%;" />

3. 双重模式提供保护的手段是将可能引起损害的机器指令作为**特权指令**，并且硬件只有在**内核模式**才能执行这些特权指令。如果在**用户模式**下试图执行特权指令，硬件不会执行，而是认为其非法并**以陷阱形式通知操作系统**。操作系统会给出一个适当的出错信息，并倒出程序内存，写到文件以供检查。

4. 特权指令包括**切换到用户模式，IO控制，定时器管理和中断管理**等。（切换到内核模式是可以由用户程序来执行的，所以不是特权指令）

5. 系统调用有多种方式，但无论哪种方式都是进程请求操作系统执行功能的方法。系统调用会**陷入（trap指令）**中断向量指定的某个位置。当要执行系统调用时，硬件会将其当成软件中断（陷阱），控制经中断向量转移到系统的中断服务程序。内核检查中断指令（的参数）并判断系统调用类型。请求的其他信息可以通过寄存器、堆栈和内存进行传递。内核检查参数是否合法并执行请求。最后，**控制返回到系统调用之后的指令。**

##### 二. 定时器

1. 为防止用户程序陷入死循环或在不调用系统服务时不将控制返回到操作系统，操作系统使用了定时器。定时器可设置为在指定周期后中断计算机。**周期可以是可变或固定的。**
2. 在将控制交到用户之前，操作系统要确保定时器已经设置好以便产生中断。**当定时器中断时，控制自动转到操作系统。**操作系统可以决定将该中断作为错误处理，或是给程序更多时间。

#### 1.6 进程管理

1. 进程为了完成任务，需要一定的资源，包括cpu时间、内存、文件、IO设备等。这些资源可以在进程创建时赋予，也可以在执行进程时分配。当进程中止时，操作系统会收回所有可以再利用的资源。
2. <a href="#difference_between_process_and_procedure">程序本身不是进程</a>。**程序是一个被动实体，进程是一个主动实体。**
3. 进程是系统的工作单元，系统由多个进程组成，包括操作系统进程和用户进程。
4. 操作系统负责以下活动：在cpu上调度进程和线程、创建和删除用户和系统进程、挂起和重启进程、提供进程同步和通信机制。

#### 1.7 内存管理

1. 如果一个程序需要执行，那么它必须**映射到绝对地址并加载到内存**。随着程序执行，进程可以通过产生绝对地址来访问内存的程序指令和数据。程序终止时它的内存会释放，一边后续程序的加载和执行。
2. 内存管理的方案需要有特定算法以适用于特定场景。每个算法都需要特定的硬件支持。
3. 操作系统负责以下活动：记录内存的哪部分在被使用以及被谁使用、决定哪些进程会调入调出内存、根据需要分配和释放内存空间。

#### 1.8 存储管理

1. 文件管理：创建和删除文件、创建和删除目录（以组织文件）、提供文件和目录的操作原语、映射文件到外存、备份文件到稳定非易失的存储介质。
2. 大容量存储器管理：管理空闲空间、存储空间分配、硬盘调度。
3. 高速缓存（cache）：慎重选择高速缓存大小和置换策略可以极大提高性能。
4. IO系统：操作系统的目的之一时为用户隐藏具体硬件设备的特性。

#### 1.9 保护与安全

1. 需要有机制确保只有经过操作系统授权，进程才能使用相应资源。这种机制就是**保护**。
2. 防止系统不受内部或外部攻击是**安全**的工作。为了阻止攻击，有些系统让操作系统完成，其他系统让策略或额外软件来完成。
3. 保护和安全要求系统能区分所有用户。大多数操作系统采用一个列表，以便维护用户名称及其关联用户标识。也有系统区分用户集合。

### 第二章 操作系统结构

####  2.1 操作系统的服务

1. 操作系统提供环境以便执行程序。有一组服务**用于提供用户功能**：
   - 用户界面：有多种形式，包括命令行界面、批处理界面和图形用户界面。
   - 程序执行：系统加载程序加载程序到内存并加以运行。程序应能结束运行，无论是正常还是不正常。
   - IO操作：程序运行可能需要IO，操作系统必须提供手段以便执行IO。
   - 文件系统操作：读写文件和目录，创建删除文件，搜索文件，列出文件信息。有些操作系统还提供权限管理。
   - 通信：可以通过共享内存或消息交换实现。
   - 错误检测：操作系统需要不断检测错误和更正错误。有时只能停机，有时可以终结出错进程，或返回出错码。
2. 还有一组操作系统服务是为了**确保系统本身运行高效**：
   - 资源分配：为多个作业分配资源。
   - 记账：记录用户使用资源的类型和数量。
   - 保护和安全：保护需要确保可以控制系统资源的全部访问。系统安全保证不受内外部攻击。

<img src="pic/2-1.jpg" style="zoom:50%;" />

#### 2.2 用户与操作系统的界面

##### 一. 命令解释程序

1. 命令解释程序允许用户直接输入命令，以供操作系统执行。有的操作系统内核包括命令解释程序，有的操作系统将其当成一个特殊程序，当用户首次登录或一个任务开始时该程序就会运行。对于有多个可选命令解释程序的系统，解释程序称为壳(shell)。
2. 命令解释程序的主要功能是，获取并执行用户指定的下一条命令。这些命令的实现有两种常用方法：
   - 命令解释程序本身包含代码以执行这些命令。对于这种方法，所能提供命令的数量决定命令解释程序的大小。
   - 通过系统程序实现大多数的命令。命令解释程序不必理解命令，只要通过命令确定一个文件以加载到内存并执行。

##### 二. 图形用户界面

1. 利用桌面概念，即采用基于鼠标的视窗和菜单系统。

##### 三、界面的选择

1. 选择命令行界面或GUI主要取决于个人喜好。
2. 用户界面可随系统的不同甚至系统用户的不同而不同，它通常不属于系统内核。

#### 2.3 系统调用

1. 系统调用提供**操作系统服务接口**。

2. 系统每秒执行成千上万的系统调用，但大多数程序员不会看到这些细节。通常，开发者根据API来设计程序。API为方便应用程序员规定了一组函数，包括每个函数的输入参数和返回值。有三组常见的API：适用于Windows的Windows API、适用于POSIX系统（包括所有版本的UNIX、Linux和OS X）的POSIX API和适用于Java虚拟机的Java API。

3. 在后台，API函数通常为应用程序员调用实际的系统调用。

4. 根据API来编程能够提高程序的可移植性。

5. 对于大多数的程序设计语言，运行时支持系统（函数库）提供了系统调用接口以链接到操作系统的系统调用。系统调用接口截取API函数的调用，并调用所需的系统调用。每个系统调用有一个相关数字，接口根据数字来建立索引列表。

   <img src="pic/2-2.jpg" style="zoom:50%;" />

   

6. 向操作系统传递参数有三种常用方法：通过寄存器传递参数；将参数存在内存的块或表中，通过寄存器传递地址；将参数压入堆栈，通过操作系统弹出。后两种方式不限制传递参数的数量或长度。

#### 2.4 系统调用的类型

##### 一. 进程控制

1. 执行程序应能正常(end( ))或异常(abort( ))停止执行，如果一个系统调用异常停止当前执行的程序，或程序运行遇到问题并引起错误陷阱，就将内存信息转储到磁盘并生成错误信息，便于纠正错误。**无论是正常还是异常情况，操作系统都应将控制转到命令解释程序。**
2. 执行一个程序的进程或作业可能需要加载(load( ))和执行(execute( ))另一个程序。这种功能允许命令解释程序来执行一个程序。
3. 创建了新的作业或进程后，可能要等待其执行完成，也可能要等待某个事件的出现。
4. 通常，两个或多个进程会共享数据。为了确保共享数据的完整性，操作系统通常提供系统调用以允许一个进程锁定共享数据。在解锁之前，其他进程不能访问该数据。

##### 二. 文件管理

1. 首先要能创建和删除文件。这两个系统调用需要文件名称和文件的一些属性。
2. 一旦文件创建后，就会打开并使用它，也会读、写、重定位。最后，需要关闭文件。
3. 如果采取目录结构组织文件系统的文件，那么也需要同样的目录操作。
4. 不管是文件还是目录，都要能对各种属性的值加以读取或设置。
5. 有的操作系统还提供其他的系统调用，包括文件复制、移动。

##### 三. 设备管理

1. 进程执行需要一些资源。操作系统控制的各种资源可以看作设备。有的设备是物理设备，有的设备可当作抽象或虚拟的设备。多用户系统要求先请求设备，在设备使用完后要释放它。
2. 在请求并得到设备后，就能像对待文件一样对设备进行读、写、重定位。

##### 四. 信息维护

1. 用于**在程序与操作系统之间传递信息**。
2. 大多数系统都有一个返回当前时间和日期的系统调用。还有的系统调用可以返回系统的其他信息，如当前用户数、操作系统版本和内存或磁盘的可用量等。
3. 还有一组系统调用帮助调试程序，包括转储内存、单步（cpu每执行一条指令都会产生一个陷阱）。
4. 操作系统维护所有进程的信息，可以通过系统调用来访问。

##### 五. 通信

1. 对于<a href="#message_communicating_system">消息传递模型</a>，进程通信通过相互交换消息来传递信息。进程间的消息交换可以直接执行，也可通过一个共同邮箱来间接进行。
2. 对于<a href="#shared_memory_system">共享内存模型</a>，进程通过系统调用创建共享内存，并访问其他进程拥有的内存区域。
3. 消息传递对少量数据的交换很有用，共享内存在通信方面比较高速和便捷，但在保护和同步方面有问题。

##### 六. 保护

1. 提供保护的系统调用包括设置资源权限和允许或拒绝特定用户访问某些资源。

#### 2.5 系统程序

1. 系统程序也称为系统工具，为程序开发和执行提供了一个方便的环境。有的系统程序只是系统调用的简单用户接口，有的相当复杂。系统程序可分为：文件管理、状态信息、文件修改、程序语言支持、程序加载与执行、通信、后台服务。
2. 除系统程序外，大多数操作系统提供解决常见问题或执行常用操作的程序，包括网页浏览器、文字处理器、数据库系统、编译器等。

#### 2.6 操作系统的设计与实现

##### 一. 设计目标

1. 用户目标：用户要求系统有一定的优良性能。
2. 系统目标：操作系统应易于设计、实现和维护。

##### 二. 机制和策略

1. **机制决定如何做，策略决定做什么。**一个重要原则就是策略和机制的分离。
2. 对于所有的资源分配，策略决定非常重要。只要决定是否分配资源，就应做出策略决定。

##### 三. 实现

1. 早期系统是用汇编语言编写的，现在大部分操作系统用高级语言实现。实际上，操作系统可以由多种语言编写，底层使用汇编语言，高层使用高级语言。
2. 采用高级语言的优势在于代码编写更快、更为紧凑、更容易理解和调试、更容易移植到其他硬件，缺点在于速度的降低和存储的增加。
3. 操作系统的重大性能改善很可能来源于更好的数据结构和算法。

#### 2.7 操作系统的结构

##### 一. 简单结构

1. 利用最小空间而提供最多功能，因此没有仔细地划分成模块。

<img src="pic/2-3.jpg" style="zoom:50%;" />

##### 二. 分层方法

1. 有了适当的硬件支持，操作系统可以分成许多块，这样操作系统可以更好地控制计算机和使用计算机的应用程序。采用自顶向下方法，可先确定总的功能和特征，再划分成模块。
2. 系统的模块化有许多方法，其中一种是分层法，即操作系统分成若干层级。最低层（层0）是硬件，最高层（层N）是用户接口。操作系统层采取抽象对象，以包括数据和操纵这些数据的操作。如层M，包括了数据结构和一组可被更高层调用的程序集，而层M可以调用更低层的操作。

<img src="pic/2-4.jpg" style="zoom:50%;" />

3. 分层法的优点在于简化了构造和调试，因为每层的实现只是利用更低层的操作。
4. 分层法的难点在于如何合理定义各层。由于每层只能利用更低层的功能，因此有必要仔细规划。同时，由于每层都为系统调用增加了额外开销，分层实现的效率会比其他方法较差。

##### 三. 微内核

1. 微内核技术通过从内核中删除所有不必要的部件，而将他们当作系统级与用户级的程序来实现，以将内核模块化。这样会使内核较小。
2. 微内核的主要功能是为客户端程序和运行在用户空间的各种服务提供通信。通信是通过消息传递来提供的。
3. 微内核的优点是便于扩展操作系统，因为新服务可以在用户空间内添加；当内核确实需要修改时，所做修改也会很小。而且，微内核的可移植性、安全性和可靠性都更好。
4. 微内核的缺点是，由于增加的系统功能的开销，微内核的性能会受损。

##### 四. 模块

1. 操作系统的设计采取**可加载的内核模块形式**。内核有一组核心组件，在启动或运行时，内核都可以**通过模块链入额外服务**。
2. 这种设计的思想是：内核提供核心服务，其他服务可以在内核运行时动态实现。

### 第三章 进程

#### 3.1 进程概念

##### 一. 进程

1. <a name="difference_between_process_and_procedure">**进程是执行的程序，但不只是程序代码。**</a>进程还包括当前活动，如程序计数器的值和处理器寄存器的内容等。另外，进程通常还包括进程堆栈、数据段和堆（进程运行时动态分配的内存）。

<img src="pic\3-1.jpg" style="zoom:50%;" />

2. 虽然两个进程可以与同一程序相关联，但是当作两个单独的执行序列。进程在运行时也经常会生成许多进程。
3. 进程本身也可以作为一个环境，用于执行其他代码。
4. 进程的五大特征：**动态性、异步性、并发性、独立性、结构上是由程序段、数据段和PCB组成的。**

##### 二. 进程状态

1. 每个进程可能处于以下状态：
   - 新的（new）：进程正在创建。
   - 运行（running）：指令正在执行。
   - 等待（waiting）：进程等待发生某个事件（如IO完成或收到信号）。
   - 就绪（ready）：进程等待分配处理器。
   - 终止（terminated）：进程已经完成执行。
   
   <img src="pic/3-2.jpg" style="zoom:50%;" />

##### 三. 进程控制块（PCB）

1. 操作系统内的每个进程表示，采用**进程控制块（PCB）**，也称为任务控制块。它包含许多与特定进程相关的信息：

   - 进程状态
   - 程序计数器：进程将要执行的下个指令的地址
   - cpu寄存器
   - cpu调度信息：包括进程优先级、调度队列的指针和其他调度参数
   - 内存管理信息：包括基地址、界限寄存器的值、页表或段表
   - 记账信息：包括cpu时间、实际使用时间、时间期限、记账数据、作业或进程数量
   - IO状态信息：包括分配给进程的IO设备列表、打开文件列表

   <img src="pic/3-3.jpg" style="zoom:50%;" />

##### 四. 线程

   1. 许多现代操作系统扩展了进程概念，以便一次能够执行多个线程。在支持线程的系统中，PCB被扩展到包括每个线程的信息。
   2. **Linux的PCB采用C语言结构体task_struct来表示。**在Linux内核中，所有活动进程的表示都采用task_struct的双向链表。内核采用一个current指针用于指向当前系统正在执行的进程。

#### 3.2 进程调度

##### 一. 调度队列

1. 进程在进入系统时，会被加到**作业队列**，这个队列包括系统内的所有进程。
2. 驻留在内存中的、就绪的、等待运行的进程保存在**就绪队列**上。这个队列通常用链表实现，头节点有两个指针，用于指向链表的第一个和最后一个PCB块；每个PCB块还包括一个指针，指向就绪队列的下一个PCB。
3. 一个共享设备可能会收到多个进程的IO请求，有的进程需要等待。等待特定IO设备的进程列表称为**设备队列**。每个设备都有自己的设备队列。

<img src="pic/3-4.jpg" style="zoom:50%;" />

4. 进程调度通常用队列图来表示。最初，新进程被加到就绪队列并等待，直到被选中执行或分派。当该进程被分配到cpu并执行时，以下事件可能发生：

   - 进程可能发出IO请求，并被放到IO队列。

   - 进程可能创建一个新的子进程，并等待其终止。

   - 进程可能由于中断而被强制释放cpu，并被放回到就绪队列。

   进程会重复以上循环直到终止，然后从所有队列中删除，其PCB和资源也被释放。

<img src="pic/3-5.jpg" style="zoom:50%;" />

##### 二. 调度程序

1. 进程在整个生命周期中会在各种调度队列之间迁移。操作系统为了调度必须按一定方式从这些队列中选择进程。进程选择通过适当调度器或调度程序来执行。主要有两种调度程序：

   - 长期调度程序：又称作业调度程序，从磁盘的缓冲池中选择进程加到内存以便执行。
   - 短期调度程序：又称cpu调度程序，从准备执行的进程中选择进程并分配cpu。

   这两种调度程序的主要区别是执行频率。短期调度程序必须经常为cpu选择新的进程，通常每100ms至少执行一次，这导致短期调度程序必须快速。长期调度程序执行并不频繁，在新进程的创建之间通常有几分钟间隔。

2. 长期调度程序控制**多道程序程度，即内存中的进程数量**。长期调度程序应进行认真选择，保证IO密集型和cpu密集型的合理进程组合，以使系统平衡和性能得到优化。

3. 有的系统可能没有或极少采用长期调度程序，如UNIX和WIndows，只是将新进程放在内存供短期调度程序使用。

4. 有的分时系统可能引入一个额外的**中期调度程序**，其核心思想是可**将进程从内存或cpu竞争中移出，从而降低多道程序程度。**之后，进程可被重新调入内存，并从中断处继续执行。这种方案被称为**交换**。

<img src="pic/3-6.jpg" style="zoom:50%;" />

##### 三. 上下文切换

1. 中断导致cpu从执行当前任务改变到执行内核程序。当中断发生时，系统需要保存当前运行在cpu上的进程的上下文，一百年在处理后能够恢复上下文，即先挂起进程，再恢复进程。进程上下文采用PCB表示。通常，通过执行状态保存保存cpu当前状态（包括模式）；之后，状态恢复重新开始运行。
2. 切换cpu到另一个进程需要保存当前进程状态和恢复另一个进程的状态，这个任务就是上下文切换。当进行上下文切换时，内核会将旧进程状态保存在其PCB中，然后加载经调度而要执行的新进程的上下文。
3. 上下文切换的时间是纯粹的开销，因为切换时系统没有做任何有用工作。其典型速度是几毫秒。

#### 3.3 进程运行

##### 一. 进程创建

1. 进程再执行过程中可能创建多个新的进程。**创建进程称为父进程，新进程称为子进程。**每个新进程可以再创建其他进程，从而形成进程树。

2. 大多数操作系统对进程的识别是采用唯一的**进程标识符（pid）**，这通常是一个整数值。系统内的每个进程都有一个唯一的pid，它可以用做索引，以便访问内核中进程的各种属性。

3. Linux系统中，**进程init（pid始终为1）作为所有用户进程的根进程或父进程**。一旦系统启动后，init进程可以创建各种用户进程。对于UNIX和Linux系统，我们可以通过ps命令得到一个进程列表。

4. 当一个进程创建子进程时，子进程所需的资源可以从操作系统直接获得，也可以只从父进程那里获得资源子集。父进程可能要在子进程之间分配资源或共享资源，限制子进程只能使用父进程的资源，可以防止创建过多进程，导致系统超载。除了提供各种物理和逻辑资源外，父进程也可能向子进程传递初始化数据或输入。

5. 当进程创建新进程时，可能有两种执行可能：

   - 父进程与子进程并发执行
   - 父进程等待，直到某个或全部子进程执行完。

   新进程的地址空间也有两种可能：

   - 子进程是父进程的复制品，两者有同样的数据和程序
   - 子进程加载另一个新程序

6. 在UNIX中，通过系统调用fork() 可创建新进程。新进程的地址空间复制了原来进程的地址空间，这使得父进程和子进程可以轻松通信。通常，在系统调用fork() 之后，有个进程使用系统调用exec() ，以用新程序来取代进程的内存空间，这破坏了原来程序的内存内容。因此，**除非调用exec() 出现了错误，否则不会返回控制**。

<img src="pic/3-7.jpg" style="zoom:50%;" />

7. 没有什么可以阻止子进程不调用exec() 而作为父进程的副本来执行。在这种情况下，父进程和子进程会并发执行，并使用同样的代码指令。当然，两者都有各自的数据副本。
8. 在Windows中，进程创建采用Windows API函数CreateProcess() 。它与fork() 不同的地方在于其要求将一个特定程序加载到子进程的地址空间。而且，fork() 不需要传递任何参数，但CreateProcess() 需要传递至少10个参数。

##### 二. 进程终止

1. 当进程完成执行最后语句并通过系统调用exit() 请求操作系统删除自身时，进程终止。这时，进程可以返回状态值（通常为整数0，-1，1等）到父进程（通过系统调用wait() ）。**所有进程资源会被操作系统释放**。
2. 进程通过适当系统调用可以终止另一进程。通常，只有终止进程的父进程才可以执行这一系统调用。父进程终止子进程的原因有：
   - 子进程使用了超过它所分配的资源
   - 分配给子进程的任务不再需要
   - 父进程正在退出，而且操作系统不允许无父进程的子进程继续执行
3. 有些系统不允许子进程在父进程已终止的情况下存在。对于这类系统，如果一个进程终止（无论正常与否），那么他的所有子进程都应该终止。这种现象被称为**级联终止**，通常由操作系统来启动。
4. 一个进程终止时，操作系统会释放其资源，但它位于进程表中的条目还在，直到他的父进程调用wait() ，这是因为进程表包含了进程的退出状态（父进程调用wait() 可以获取这个状态值）。但当进程已经终止，而其父进程尚未调用wait() ，这样的进程被称为**僵尸进程**。所有进程终止时都会过渡到这一状态，但一般都是短暂存在。如果父进程没有调用wait() 就终止，会导致子进程变为**孤儿进程**。Linux和UNIX的处理方法是进程init定期调用wait() 以便收集任何孤儿进程的退出状态，并释放其pid和进程表条目。

#### 3.4 进程间通信

##### 一. <a name="cooperating process">进程协作</a>

1. 如果一个进程不能影响其他进程或受其他进程影响，那么该进程是独立的，反之就是协作的。显然，**不与其他任何进程共享数据的进程就是独立进程**。
2. 进程协作的必要性：允许信息共享、加速计算、模块化和用户使用的方便性。
3. 协作进程需要有进程间通信（IPC）机制，主要有**共享内存**和**消息传递**两种基本模型。前者需要考虑同步问题，后者无需避免冲突，对交换少量数据很管用，但由于采用较多系统调用，可能会比共享内存模型要慢。

##### 二. <a name="shared_memory_system">共享内存系统</a>

1. 采用共享内存的进程间通信，需要通信进程建立**共享内存区域**。通常，一片共享内存区域驻留在创建共享内存段的进程地址空间内，其他希望使用这个共享内存段进行通信的进程应将其附加到自己的地址空间。
2. 通常操作系统会阻止一个进程访问另一进程的内存。共享内存需要两个或更多进程取消这一限制。数据的类型或位置取决于进程而非操作系统。同时，进程负责确保他们不向同一位置同时写入数据。
3. 为了解决共享内存的进程并发执行的问题，应有一个可用的缓存区以供获取数据。缓冲区可以分无界（不限制缓冲区的大小）和有界缓冲区（缓冲区固定大小）。

##### 三. <a name="message_communicating_system">消息传递系统</a>

1. 消息传递提供一种机制，以便允许进程不必通过共享地址空间来实现通信和同步。消息传递工具至少提供了send和receive两种操作。进程发送的消息可以是定长或变长的。如果只能发送定长消息，则系统实现会比较简单，但使编程任务变得困难。反之，编程会变得简单，而系统级实现会更加复杂。
2. 如果两个进程需要通信，那么他们必须相互发送消息和接收消息。他们之间需要有**通信链路**。该链路的实现有很多方法，以下是几种用于逻辑实现链路和send和receive等操作的方法：
   - 直接或间接的通信
   - 同步或异步的通信
   - 自动或显式的缓冲

3. 命名：需要通信的进程应有一个办法以便互相引用。
   - 对于直接通信，**需要通信的每个进程必须明确指定通信的接收者或发送者**。这种方案的通信链路有以下属性：在需要通信的每对进程之间自动建立链路，只需要直到对方身份就可以交流；每个链路只与两个进程相关；每对进程之间只有一个链路。
   - 这种方案展现了寻址的对称性，即发送和接收进程必须指定对方。一个变形方案采取了寻址的非对称性，即只要发送者指定接收者。这两个方案的缺陷是生成进程定义的有限模块化，即更改进程标识符需要修改所有旧的标识符引用。
   - 在间接通信中，**通过邮箱或端口来发送接收消息**。邮箱可以抽象成一个对象，进程可以往其中存放、删除消息，每个邮箱都有一个唯一的标识符。**一个进程可以通过多个不同的邮箱与另一个进程通信，但两个进程只有拥有一个共享邮箱时才可以通信**。这种方案有以下属性：只有在两个进程拥有一个共享邮箱时才可以通信；一个链路可以与两个或多个进程相关联；两个通信进程之间可以有多个不同链路，每个链路对应一个邮箱。
   - 如果有多个进程都共享一个邮箱，他们都对其执行receive操作，获取消息的方法有以下几种：允许一个链路最多只能与两个进程关联；允许一次最多只能有一个进程执行receive操作；允许系统随意选择一个（或定义一个算法来选择）进程接收消息。系统可以让发送者指定接收者。
   - 邮箱可以为进程或操作系统拥有。如果是进程拥有（进程的地址空间的一部分），那么需要区分所有者（只能接收消息）和使用者（只能发送消息）。如果是操作系统拥有，则其必须提供机制以允许进程创建新的邮箱、通过邮箱发送和接收消息和删除邮箱。
4. 同步：**消息传递可以是阻塞或非阻塞的，也称为同步和异步**。
   - 阻塞发送：发送进程阻塞，直到消息由接收进程或邮箱所接收。
   - 非阻塞发送：发送进程发送消息，并且恢复操作。
   - 阻塞接收：接收进程阻塞，直到有消息可用。
   - 非阻塞接收：接收进程收到一个有效消息或空消息。
5. 缓存：**不管是直接还是间接通信，通信进程交换的消息总是驻留在临时队列中。**临时队列有三种实现方法：
   - 零容量：队列的最大长度为0，因此链路中不能有任何消息处于等待。对于这种情况，发送者应阻塞，直到接收者接收到消息。
   - 有限容量：队列长度为有限的n。如果发送消息时队列未满，那么该消息可以放在队列中，且发送者可以继续执行不用等待；但如果队列已满，那发送者应阻塞，直到队列有可用的空间为止。
   - 无限容量：队列长度无限。发送者从不阻塞。

#### 3.6 客户机/服务器通信

##### 一. 套接字

1. 套接字是通信的端点。通过网络通信的每对进程需要使用一对套接字。**每个套接字由一个IP地址和一个端口号组成**。
2. 通常，套接字采用客户机-服务器架构。服务器通过监听指定端口来等待客户请求。服务器收到请求后，接受来自客户套接字的连接，从而完成连接。
3. 使用套接字的通信虽然常用且高效，但是属于**分布式进程之间的一种低级形式的通信**。一个原因是套接字只允许在通信线程之间交换无结构的字节流，客户机或服务器程序需要自己加上数据结构。

##### 二. 远程过程调用（RPC）

1. RPC对于通过网络连接系统之间的过程调用进行了抽象。它在许多方面都类似于IPC机制，且通常建立在IPC之上。但与IPC的消息不一样的是，**RPC通信交换的消息有明确结构**。
2. RPC允许客户调用位于远程主机的过程。通过客户端提供的存根，RPC通常隐藏通信细节。
3. 为了解决客户机和服务器系统的不同数据表示（大小端序），许多RPC系统定义一个独立于机器的数据表示（外部数据表示，XDR）。
4. 客户机有两种方式知道服务器上的端口：
   - 在编译时，RPC调用有一个与它关联的固定端口。
   - 绑定通过交会机制动态进行。

##### 三. 管道

1. 管道允许两个进程进行通信。
2. 普通管道：允许两个进程按标准的生产者-消费者方式通信，即生产者向管道的写入端写，消费者从读出端读。因此，**普通管道是单向的**。如需要双向通信，需要采用两个管道。普通管道只能由创建进程访问。对于Windows系统，普通管道被称为匿名管道，其行为类似于UNIX管道。要注意的是，对于UNIX和Windows系统，**采用普通管道的进程通信需要有父子关系**，即这些管道只可用于同一机器的进程间通信。
3. 命名管道：命名管道的通信可以是双向的，并且父子关系不是必须的。当建立了一个命名管道后，多个进程都可用它通信。此外，当进程通信完成后，命名管道继续存在（普通管道会在进程完成通信并终止后消失）。UNIX和Windows的命名管道实现细节有很大不同。UNIX的命名管道是FIFO，一旦创建就表现为文件系统的典型文件。FIFO会一直存在直到被文件系统显式删除。虽然FIFO允许双向通信，但它只允许**半双工传输（数据在同一时间只能按一个方向传输）**，所以双向传输一般使用两个FIFO。此外，如果需要不同系统的通信，应使用套接字。Windows的命名管道通信机制更加丰富，允许**全双工通信（数据在同一时间可以双向传输）**，且通信进程可以在不同机器。Windows的命名管道支持字节流或消息流的数据，而FIFO只支持字节流。

### 第四章 多线程编程

#### 4.1 概述

##### 一. 线程概念

1. 每个线程是**cpu使用的一个基本单元**，它包括线程ID、程序计数器、寄存器组和堆栈。他与统一进程的其他线程共享代码段、数据段和其他操作系统资源。
2. 每个传统进程只有单个控制线程。如果一个进程具有多个控制线程，那么他能同时执行多个任务。

<img src="pic/4-1.jpg" style="zoom:50%;" />

##### 二. 动机

1. 现代计算机运行的大多数应用程序都是多线程的，一个应用程序通常作为具有多个控制线程的一个进程来实现。
2. 在有些情况下，单个应用程序可能需要执行多个类似任务，如web服务器。如果一个web服务器作为单个线程的传统进程来执行，那么一次只能执行一个请求，影响速率。一种解决方式是让服务器作为单个进程运行以便接受请求，当服务器收到请求时再创建另一个进程以便处理请求。但进程的创建很浪费时间和资源，且这些开销是不必要的。
3. 如果服务器进程是多线程的，那么服务器可以创建一个单独线程以便监听客户请求。当有请求时，服务器不是创建进程而是创建线程以处理请求，并恢复监听其他请求。

<img src="pic/4-2.jpg" style="zoom:50%;" />

4. 线程在远程过程调用系统中也有重要作用。

5. 大多数的操作系统内核现在都是多线程的，每个线程执行一个特定任务。

##### 三. 优点

1. 响应性：如果一个交互程序采用多线程，那么即使部分阻塞或执行冗长操作，它仍可以继续执行，从而增加对用户的响应程度。

2. 资源共享：进程只能通过共享内存或消息传递来共享资源，但线程默认共享他们所属进程的内存和资源。这允许了一个应用程序在统一地址空间内有多个不同活动进程。
3. 经济：进程创建所需的内存和资源分配十分昂贵。由于线程能够共享他们所属进程的资源，所以创建和切换线程更加经济。
4. 可伸缩性：对于多处理器体系结构，多线程的优点更大，因为线程可在多处理核上并行运行。

#### 4.2 多核编程

##### 一. 多核/多处理器系统

1. 多线程编程提供机制，以便更有效地使用多个计算核和改进的并发性。
2. 并行性和并发性的区别：并行系统可以同时执行多个任务，而并发系统支持多个任务，允许所有任务都能取得进展（通过cpu调度）。所以，没有并行，并发也是可能的。
3. 编程挑战：**如何更好地使用多个计算核？**
   - 识别任务：分析应用程序，查找区域以便分为独立的、并发的任务。
   - 平衡：在识别可以并行运行任务时，程序员还应保证任务执行同等价值的工作。
   - 数据分割：由任务访问和操作的数据也应划分以便运行在单独的核上。
   - 数据依赖：任务访问的数据必须分析多个任务之间的依赖关系。当一个任务依赖于另外一个任务的数据时，程序员必须确保任务执行是同步的，以适应数据依赖性。
   - 测试与调试：当一个程序并行运行于多核时，许多不同的执行路径是可能的。这给测试与调试带来了困难。
4. 并行类型
   - 数据并行：注重将**数据**分布在多个计算核上，并在每个核上执行相同操作。
   - 任务并行：将**任务（线程）**而不是数据分配到多个计算核。每个线程都执行一个独立的操作。
   - 在实践中，应用程序很少严格遵循数据或任务并行，而是**混用两种策略**。

#### 4.3 多线程模型

##### 一. 多对一模型

1. 多对一模型映射多个用户级线程到一个内核线程。**线程管理是由用户空间的线程库来完成的**，因此效率更高。
2. 不过，如果一个线程执行阻塞系统调用，那么整个进程将会阻塞。
3. 因为任意时间只有一个线程可以访问内核，所以多个线程不能并行运行在多处理核系统上。所以，现在几乎没有系统继续使用该模型。

<img src="pic/4-3.jpg" style="zoom:50%;" />

##### 二. <a name="one_to_one">一对一模型</a>

1. 一对一模型映射每个用户线程到一个内核线程。
2. 该模型在一个线程执行阻塞系统调用时，能够允许另一个线程继续执行，所以并发性更好，也允许多个线程并行运行在多处理器系统上。
3. 缺点在于创建一个用户线程就要创建一个相应的内核线程，这带来的开销会影响性能。所以这种模型的大多数实现**限制了系统支持的线程数量**。
4. Linux和Windows操作系统都实现了一对一模型。

<img src="pic/4-4.jpg" style="zoom:50%;" />

##### 三. <a name="many-to-many_model">多对多模型</a>

1. 多对多模型**多路复用**多个用户级线程到同样数量甚至更少数量的内核线程。内核线程数量可能与特定应用程序或特定机器有关。
2. 虽然多对一模型允许开发人员创建任意多的用户线程，但由于内核一次只能调度一个线程，所以并未增加并发性。而一对一模型虽然有更高的并发性，但不能在应用程序内创建太多的线程。多对多模型没有这两个缺点，开发人员可以创建任意多的用户线程，并且相应内核线程可以在多处理器系统上并发执行。而且，当一个线程执行阻塞系统调用时，内核可以调度另一个线程来执行。
3. 多对多模型的一种变种在其基础上允许某个用户线程绑定到一个内核线程。这个变种有时被称为**双层模型。**

<img src="pic/4-5.jpg" style="zoom:50%;" />





#### 4.4 线程库

##### 一. 概念与实现

1. 线程库为程序员提供创建和管理线程的API。其实现方式有两种：
   - 在用户空间中提供一个**没有内核支持**的库。这意味着调用库内函数只是导致了用户空间内的一个本地函数的调用，**而非系统调用**。
   - 实现由**操作系统直接支持**的内核级的一个库。调用库中的一个API函数通常会导致对内核的系统调用。

##### 二. 主流线程库

1. Pthreads作为POSIX标准的扩展，可以提供**用户级或内核级**的库。
2. Windows线程库是用于Windows操作系统的**内核级**线程库。
3. Java线程API允许线程在Java程序中之间创建和管理。然而，由于大多数JVM实例运行在宿主操作系统之上，**Java线程API通常采用宿主系统的线程库来实现**。
4. 对于POSIX和Windows进程，**全局声明**的任何数据可被同一进程的所有线程共享。而Java没有全局数据的概念，所以线程对共享数据的访问必须加以显式安排。

##### 三. 多线程创建的常用策略

1. 异步线程：一旦父线程创建了一个子线程后，父线程就恢复自身的执行，这样父子线程会并发执行。**每个线程的运行独立于其他线程，线程间很少共享数据。**
2. 同步线程：如果父线程创建一个或多个子线程后，那么在恢复执行之前应等待所有子线程的终止（分叉-连接策略）。一旦每个线程完成了它的工作，他就会终止并与父线程连接。只有所有子线程都连接后，父线程才恢复执行。**通常，同步线程涉及线程之间的大量数据的共享。**

#### 4.5 隐式多线程

##### 一. 隐式线程

1. 概念：将多线程的创建与管理交给**编译器和运行时库**来完成。

##### 二. 线程池

1. 主要思想：在进程开始时创建一定数量的线程，并加到池中以等待工作。当服务器收到请求时，唤醒池内的一个线程（如果有可用线程），并将需要服务的请求传递给它。一旦线程完成了服务，它会返回到池中再等待工作。如果池内没有可用线程，那么服务器会等待，直到有空线程为止。
2. 线程池的优点
   - 用现有线程服务请求比等待创建一个线程更快。
   - 线程池限制了任何之后可用线程的数量。这对那些不能支持大量并发线程的系统非常重要。
   - 将要执行的任务从创建任务的机制中分离出来，允许我们采用不同策略运行任务。
3. 池内线程的数量可以通过一些因素来加以估算，如系统cpu数量、物理内存的大小和并发客户请求数量的期望值等。高级线程池架构可以根据使用模式动态调整池内线程数量。

##### 三. OpenMP

1. 是**一组编译指令和API**，支持共享内存环境下的并行编程。
2. 当OpenMP遇到指令#pragma omp parallel时，它会创建与系统处理核一样多的线程，然后同时执行并行区域。当每个线程退出并行区域时，也就终止了。

##### 四. 大中央调度（GCD）

1. 是Apple Mac OS X和iOS操作系统的一种技术，是C语言、API和运行时库的**一组扩展**，允许应用程序开发人员将某些代码区段并行运行。**GCD管理大多数的多线程细节**。
2. GCD为C和C++增加了**块**的扩展。每块只是工作的一个独立单元。通过将块放置在调度队列上，GCD调度块以便执行。
3. 在内部，GCD的线程池由POSIX线程组成。GCD根据应用需求和系统容量来动态调节线程数量，从而实现对池的管理。

#### 4.6 多线程问题

##### 一. 系统调用fork()和exec()

1. 如果程序内的某个线程调用fork()，那么新进程复制所有线程，或者新进程只有单个线程（调用了fork()的线程）。
2. 系统调用exec()的工作方式与单线程进程相同，即参数指定的程序会代替整个进程，包括所有线程。

##### 二. 信号处理

1. UNIX信号用于通知进程某个特定时间已经发生。信号的接收可以是同步或异步的，**取决于事件信号的来源和原因**。所有信号遵循相同的模式：

   - 信号是由特定事件的发生而产生的。
   - 信号被传递给某个进程。
   - 信号一旦收到就应处理。

2. **同步信号发送到由于执行操作导致这个信号的同一进程。**当一个信号是由运行程序以外的事件产生的，该进程就异步接收这一信号。**异步信号通常发送到另一个进程。**

3. 信号处理程序

   - 缺省的信号处理程序：由内核来运行。
   - 用户定义的型号处理程序：改写缺省程序。

4. 多线程的信号传递

   - 传递信号到信号所适用的线程。
   - 传递信号到进程内的每个线程。
   - 传递信号到进程内的某些线程。
   - 规定一个特定线程以接收进程的所有信号。

   信号传递方法取决于产生信号的类型。大多数多线程版的UNIX允许线程指定它接收和拒绝什么信号。因此，在有些情况下，一个异步信号只能传递给那些不拒绝它的线程。但由于信号只能处理一次，所以**信号通常传递给第一个不拒绝它的线程**。
   
5. 虽然Windows不显式提供信号支持，但允许它们通过**异步过程调用（APC）**来模拟。APC允许用户进程指定一个函数以便用户线程收到特定事件通知时能被调用。

##### 三. 线程撤销

1. 线程撤销是指在线程完成之前终止线程。需要撤销的线程被称为**目标线程**。目标线程的撤销可以有两种情况：
   - 异步撤销：一个线程立即终止目标线程。
   - 延迟撤销：目标线程不断检查它是否应终止，这允许目标线程有机会有序终止自己。
2. 如果资源已经分配给已撤销的线程，或目标线程正在更新与其他线程一起共享的数据等，撤销会有困难。通常，操作系统收回撤销线程的系统资源，但**不收回所有资源**。因此，异步撤销线程可能不会释放必要的系统资源。
3. 对于延迟撤销，一个线程指示目标线程会被撤销。不过，仅当目标线程检查到一个标志以确定它是否应该撤销时，撤销才会发生。
4. 缺省的撤销类型是延迟撤销。这样，只有当线程到达撤销点时，才会发生撤销。建立撤销点的一种技术是调用函数pthread_testcancel()。如果有一个撤销请求处于等待，那么就会调用称为清理处理程序的函数。

##### 四. 线程本地存储

1. 同一进程的线程共享进程的数据。但在某些情况下，每个线程可能需要它自己的某些数据，即**线程本地存储（TLS）**。
2. TLS与局部变量的区别是，局部变量只能在单个函数调用时才可见，而TLS在多个函数调用时都可见，类似于静态数据。

##### 五. 调度程序激活

1. 多对多模型和双层模型需要考虑内核与线程库之间的通信。这种通信允许动态调整内核线程的数量，以便确保最优性能。
2. 许多系统在实现<a href="#many-to-many_model">多对多</a>或双层模型时，在用户和内核线程之间增加一个被称为**轻量级进程（LWP）**的中间数据结构。对于用户级线程库，LWP表现为虚拟处理器，以便应用程序调度并运行用户线程。每个LWP与一个内核线程相连。为了运行高效，应用程序可能需要一定数量的LWP。

<img src="pic/4-6.jpg" style="zoom:50%;" />

3. 用户线程库与内核之间的一种通信方案被称为**调度器激活**。它的工作方式是：内核提供一组LWP给应用程序，而应用程序可以调度用户线程到任何一个可用的LWP。此外，内核应将有关特定时间通知应用程序。这个步骤被称为**回调**，它由线程库通过回调处理程序来处理。

#### 4.7 操作系统例子

##### 一. Windows线程

1. 每个Windows应用程序按照单独进程运行，每个进程可以包括一个或多个线程。Windows采用<a href="#one_to_one">一对一映射</a>。

2. 线程一般包括如下组件：

   - 线程ID，用于唯一标识线程。
   - 寄存器组，用于表示处理器状态。
   - 用户堆栈/内核堆栈：以供线程在用户/内核模式下运行。
   - 私有存储区域：用于各种运行时库和动态链接库。

   **寄存器组、堆栈和私有存储区域，通常被称为线程上下文。**

   <img src="pic/4-7.jpg" style="zoom:50%;" />

##### 二. Linux线程

1. Linux并不区分线程和进程，而是采用**任务（task）**一词。
2. 由于Linux内核的任务表达方式，可以有不同的共享层次。

###第六章 同步

#### 6.1 背景

##### 一. <a href="#cooperating process">协作进程</a>

1. 协作进程能与系统内的其他执行进程互相影响。
2. 协作进程或能直接共享逻辑地址空间（即代码和数据），或能通过文件或消息来共享数据。

##### 二. 竞争条件

1. 多个进程并发访问和操作同一数据并且执行结果域特定访问顺序有关的情况被称为**竞争条件**。
2. 为了防止竞争条件，需要确保一次只有一个进程可以操作某个数据。为做出这种保证，要求这些进程按照一定方式来同步。

#### 6.2 <a name="critical-section problem">临界区问题</a>

##### 一. 临界区

1. 临界区：是**进程中的一段代码**，进程在执行该区时可能会修改公共变量、更新一个表、写一个文件等。
2. 当一个进程在临界区内执行时，其他进程不允许在他们的临界区内执行。也就是说，没有两个进程可以在它们的临界区内同时执行。
3. 临界区问题：设计一个协议以便协作进程。在进入临界区前，每个进程应请求许可。实现这一请求的代码区段称为**进入区**，临界区之后可以有**退出区**，其他代码为剩余区。

<img src="pic/6-1.jpg" style="zoom:50%;" />

##### 二. 解决方案

1. 临界区问题的解决方案应满足如下三条要求：
   - <a name="mutual exclusion">**互斥（mutual exclusion）**</a>：如果进程p在其临界区内执行，那么其他进程都不能在其临界区内执行。
   - <a name="progress">**进步（progress）**</a>：如果没有进程在其临界区内执行，并且又进程需要进入临界区，那么只有那些不在剩余区内执行的进程可以参加选择，以便确定谁能下次进入临界区，而且这种选择不能无限推迟。
   - <a name="bounded waiting">**有限等待（bounded waiting）**</a>：从一个进程做出进入临界区的请求直到这个请求允许为止，其他进程允许进入其临界区的次数具有上限。

2. 操作系统处理临界区问题的两种常用方法：
   - **抢占式内核**：允许处于内核模式的进程被抢占
   - **非抢占式内核**：不允许处于内核模式的进程被抢占。处于内核模式运行的进程会一直运行，直到退出内核模式、阻塞或资源放弃cpu控制。
3. 非抢占式内核的数据结构基本不会导致竞争条件，因为任一时间点只有一个进程处于内核模式。但对抢占式内核而言，其需要认真设计以便确保内核数据结构不会导致竞争条件。对于<a href="#SMP">SMP</a>结构，抢占式内核更难设计，因为这些环境下两个处于内核态的进程可以同时运行在不同处理器上。
4. 抢占式内核相应更快，因为处于内核模式的进程在释放cpu之前不会运行任意长的时间，而且抢占式内核更适用于实时编程，因为他能允许实时进程抢占在内核模式下运行的其他进程。

#### 6.3 Peterson解决方案

##### 一. 概况

1. Peterson解决方案是**基于软件**的临界区问题解决方案。但由于现代计算机执行基本机器语言指令的不同方式，不能确保Peterson解决方案能正确运行在这类机器上。

2. Peterson解决方案适用于两个进程交错执行临界区与剩余区。两个进程为P~0~和P~1~。为了方便，当使用P~i~时，用P~j~来表示另一个进程，即 j == 1 - i。

3. Peterson解决方案要求两个进程共享两个数据项：int turn和boolean flag[2]。变量turn表示哪个进程可以进入临界区，数组flag表示哪个进程准备进入临界区。

##### 二. 算法

<img src="pic/6-2.jpg" style="zoom:50%;" />

1. 为了进入临界区，进程P~i~首先设置flag[i]的值为true；并且设置turn的值为j，从而表示如果另一个进程P~j~希望进入临界区，那么它可以进入。
2. 如果两个进程同时试图进入，那么turn几乎会在同时被设置成 i 和 j 。只有一个赋值语句的结果会保持，另一个的结果会被重写。变量turn的值最终决定了哪个进程会被允许先进入临界区。

##### 三. 正确性

1. 为证明Peterson解决方法的正确性，需要证明：
   - <a href="#mutual exclusion">互斥</a>成立
   - <a href="#progress">进步</a>要求满足
   - <a href="#bounded waiting">有限等待</a>要求满足
2. P~0~和P~1~不可能同时成功执行它们的while语句。而且，只要P~j~在临界区内，flag[j] == true和turn == j就同时成立。这说明互斥成立。
3. 当P~j~退出临界区时，它会设置flag[j]为false，以允许P~i~进入临界区，如果P~j~重新设置flag[j]为true，那么它也应该设置turn为i。因此由于进程P~i~执行while语句时并不改变turn的值，所以P~i~会进入临界区（进步要求满足），而且P~i~在P~j~进入临界区后最多一次就能进入（有限等待成立）。

#### 6.4 硬件同步

##### 一. 基于加锁的硬件指令

1. 对于单处理器环境，只需要在修改共享变量时禁止中断出现，就能确保当前指令流可以有序执行，且不会被抢占。由于不可能执行其他指令，所以共享变量不会被意外的修改。这种方式往往被非抢占式内核所采用。
2. 在多处理器环境下，中断禁止会很耗时，因为消息要传递到所有处理器。消息传递会延迟进入临界区，并降低系统效率。
3. 许多现代系统提供特殊硬件指令，用于检测和修改字的内容，或用于原子地交换两个字（作为不可中断地指令）。

##### 二. 示例

1. test_and_set() ：它的执行是原子的，因此，如果两个test_and_set()同时执行在不同cpu上，那么它们会按任意次序来顺序执行。其原理是，在进入临界区之前把锁置为true，在退出区将锁置为false。

   <img src="pic/6-3.jpg" style="zoom:50%;" />

2. <a name="compare_and_swap">compare_and_swap() </a>:需要三个操作数。

<img src="pic/6-4.jpg" style="zoom:50%;" />

<img src="pic/6-5.jpg" style="zoom:50%;" />

3. 上述两种算法满足互斥要求，但不满足有限等待要求。一种基于test_and_set()的有限等待算法如下：

   <img src="pic/6-6.jpg" style="zoom:50%;" />

   #### 6.5 互斥锁

   ##### 一. 概况

   1. 一个进程在进入临界区时应得到锁，在它退出临界区时释放锁。函数**acquire()** 获取锁，函数**release()** 释放锁。
   2. 每个互斥锁有一个布尔变量available，它的值表示锁是否可用。如果可用，调用acquire() 会成功，并且锁不可再用。当一个进程试图获取不可用的锁时，他会阻塞，直到锁被释放。
   3. 对于acquire() 和release() 而言，他们的调用必须原子地执行。因此，**互斥锁通常采用硬件机制来实现**。

   ##### 二. 特性

   1. 缺点：需要**忙等待**。当有一个进程在临界区中，任何其他进程在进入临界区时必须循环调用acquire() 。这种类型地互斥锁又被称为<a name="spinlock">**自旋锁**</a>，因为进程不停地旋转，以等待锁变得可用。忙等待会浪费cpu周期。
   2. 优点：当进程在等待锁时，没有上下文切换。

   #### 6.6 信号量

   ##### 一. 概述

   1. 一个信号量S是一个整型变量，他除了初始化外只能通过两个标准原子操作wait() 和signal() 来访问。

   ​                                             <img src="pic/6-7.jpg" style="zoom:50%;" /><img src="pic/6-8.jpg" style="zoom:50%;" />

   2. 在wait() 和signal() 操作中，信号量整数值的修改应不可分割地执行，即当一个进程修改信号量值时，没有其他进程能够同时修改同一信号量的值。

   ##### 二. 信号量的使用

   1. 操作系统通常区分计数信号量和二进制信号量。前者的值不受限制，而后者的值只能为0或1.因此，二进制信号量类似于互斥锁。事实上，在没有提供互斥锁的系统上，可以用二进制信号量来提供互斥。
   2. 计数信号量可以用于控制访问具有多个实例的某种资源。信号量的初值为可用资源数量。当进程需要使用资源时，对该信号量执行wait() （减少信号量的计数）操作。当进程释放资源时，需要对该信号量执行signal() （增加信号量的计数）操作。当信号量的计数为0时，所有资源都在使用中。之后，需要使用资源的继承将会阻塞，直到计数大于0。
   3. 我们也可以用信号量来解决同步问题。例如有两个并发运行的进程，P~1~有语句S~1~而P~2~有语句S~2~，只有在S~1~执行后才能执行S~2~。我们可以让两个进程共享一个信号量synch，并且初始化为0。在S~1~之后插入signal(synch)，在S~2~之前插入wait(synch)，这样就实现了语句的同步。

   ##### 三. 信号量的实现

   1. 为了克服忙等待需要，可以修改wait() 和signal() 的定义：当一个进程执行wait() 并发现信号量值不为正时，他必须等待。然而，该进程不是忙等待，而是阻塞自己。阻塞操作将一个进程放到与信号量相关的等待队列中，并且将该进程状态切换为等待状态。然后，控制转到cpu调度程序，以便选择执行另一个进程。
   2. 等待信号量S而阻塞的进程在其他进程signal() 之后，应被重新执行。这个重新执行时通过操作wakeup() 实现的，它将进程从等待状态改为就绪状态，并加到就绪队列。
   3. 这种情况下，每个信号量可以用一个结构体来实现，其中包括一个整数value和一个进程链表list。当一个进程必须等待信号量时，就被加到进程链表。操作signal() 从等待进程链表上取走一个进程，并加以唤醒。
   4. 这样实现的信号量的值可以是负数，其绝对值就是等待它的进程数。这种情况源于实现操作wait() 时互换了递减和测试的顺序。
   5. 信号量操作应原子进行。这是一个<a href="#critical-section problem">临界区问题</a>。单处理器系统可以禁止中断。对于多处理器系统，应提供其他加锁技术，如<a href="#compare_and_swap">compare_and_swap() </a>或<a href="#spinlock">自旋锁</a>。

   ##### 四. 死锁与饥饿

   1. 死锁：具有等待队列的信号量实现可能导致这样的情况：两个或多个进程无限等待一个事件，而该事件只能由这些等待进程之一来产生。这里的事件是执行操作signal() 。当出现这种状态时，这些进程就是死锁。
   2. 饥饿：又称无限阻塞，即进程无限等待信号量。如果对与信号量有关的链表按照LIFO顺序来增加或删除进程，那么可能发生无限阻塞。

   ##### 五. 优先级的反转

   1. 如果一个较高优先级的进程需要读取或修改内核数据，而这个内核数据正在被较低优先级的进程访问，那么就会出现一个调度挑战。由于内核数据通常加锁，较高优先级的进程将不得不等待较低优先级的进程用完资源，如果较低优先级的进程被中等优先级的进程抢占，那情况会更加复杂。
   2. 优先级反转只出现在具有两个以上优先级的系统中，因此一个解决方案是只有两个优先级，但这是不够的。所以一些系统采用了优先级继承协议。根据这个协议，所有正在访问资源的进程获得需要访问它的更高优先级的进程的优先级。

